{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T15:21:49.710211Z",
     "start_time": "2024-05-27T15:21:37.233687Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T15:33:56.263252Z",
     "start_time": "2024-05-27T15:33:55.686208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets , models , transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ],
   "id": "d55371a878d3d9a7",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets , models , transforms\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchsummary\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torchvision'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T15:13:32.940174Z",
     "start_time": "2024-05-27T15:13:32.926097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = '\\data_input\\image'\n",
    "dataset = datasets.ImageFolder(data_path)\n",
    "num_samples = len(dataset)"
   ],
   "id": "e2f9f8aa0cc8eadf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Seni\\AppData\\Local\\Temp\\ipykernel_22516\\2631649728.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  data_path = '\\data_input\\image'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## preprocess",
   "id": "ee1f2c4800cd784a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TRAIN_RATIO , VALID_RATIO = 0.8 , 0.1\n",
    "n_train_examples = int( num_samples * TRAIN_RATIO )\n",
    "n_valid_examples = int( num_samples * VALID_RATIO )\n",
    "n_test_examples = num_samples - n_train_examples - n_valid_examples\n",
    "\n",
    "train_dataset , valid_dataset , test_dataset = dataset.random_split( dataset ,\n",
    "                                                                     [n_train_examples, n_valid_examples, n_test_examples]\n",
    ")"
   ],
   "id": "bdb33b5e545461ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "IMG_SIZE = 224\n",
    "train_transforms = transforms.Compose ([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE ) ) ,\n",
    "    transforms.RandomHorizontalFlip() ,\n",
    "    transforms.RandomRotation(0.2) ,\n",
    "    transforms.ToTensor() ,\n",
    "    transforms.Normalize([0.5 , 0.5 , 0.5], [0.5 , 0.5 , 0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE , IMG_SIZE ) ) ,\n",
    "    transforms.ToTensor() ,\n",
    "    transforms.Normalize([0.5 , 0.5 , 0.5] , [0.5 , 0.5 , 0.5])\n",
    "])\n",
    "\n",
    "train_dataset.dataset.transform = train_transforms\n",
    "valid_dataset.dataset.transform = test_transforms\n",
    "test_dataset.dataset.transform = test_transforms"
   ],
   "id": "6c91064ebacbf8ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = dataset.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_dataloader = dataset.DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size=BATCH_SIZE \n",
    ")\n",
    "test_dataloader = dataset.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ],
   "id": "ef45d8ecd94808f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac3201eb26ffc86c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27dff0a82cc6b2ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c8205a469e0f1949"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f84e9713aadd3831"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_model(input_1, input_2, input_3):\n",
    "    cnn_input = Input(shape=(input_1, input_2, input_3), name='CNN Input')\n",
    "    cnn1 = Conv2D(filters=32, kernel_size=(3,3), activation='relu')(cnn_input)\n",
    "    cnn1 = BatchNormalization()(cnn1)\n",
    "    cnn1 = MaxPooling2D(pool_size=2)(cnn1)\n",
    "    cnn2 = Conv1D(filters=16, kernel_size=(3,3), activation='relu')(cnn1)\n",
    "    cnn2 = BatchNormalization()(cnn2)\n",
    "    cnn2 = MaxPooling2D(pool_size=2)(cnn2)\n",
    "    ft = Flatten()(cnn2)\n",
    "    dns1 = Dense(64, activation='relu')(ft)\n",
    "    dns2 = Dense(32, activation='relu')(dns1)\n",
    "    dns3 = Dense(32, activation='relu')(dns2)\n",
    "    output1 = Dense(1, name='length', activation = 'relu')(dns3)\n",
    "    output2 = Dense(1, name='width', activation = 'relu')(dns3)\n",
    "    output3 = Dense(1, name='taillength', activation = 'relu')(dns3)\n",
    "    model = Model(inputs=cnn_input, outputs=[output1, output2, output3])\n",
    "    optimizer = Adam(0.0001)\n",
    "    model.compile(optimizer=optimizer, loss={'length': 'mae', 'width': 'mae', 'taillength': 'mae'})\n",
    "return model\n",
    "Then you can call build_model using height, width and channel lenght of your input images.\n",
    "The training with be something like model.fit(X, [y_0, y_1, y_2], epochs = your choice, batch_size = your choice, validation_data = ([Xval], [yval_0, yval_1, yval_2]))"
   ],
   "id": "1808ec46fd26d590"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
